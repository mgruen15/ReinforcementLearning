{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnaQe - A Q-Learning Network playing Snake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the the agent, execute the code cell below. Please note, that you will have to wait for 10-15 seconds until you rearrange the windows as the code will produce a thread error otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python agent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the agent and model can be found in <code>agent.py</code> and <code>model.py</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning progress plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the training progress of the agent, below are the progress plots for the best agent configuration, which was trained for 490 episodes. The detailed training history with plots every 10 episodes can be found in the folder <code>./training_progress/</code> in this repository.\n",
    "\n",
    "Note, that the score in the top right hand corner is the current record of the agent. While the blue line is tracking the scores of the agent, the green dotted line shows the average score of the agent up to the respective point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_50.png)\n",
    "*The training progress of the best agent configuration after 50 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_100.png)\n",
    "*The training progress of the best agent configuration after 100 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_150.png)\n",
    "*The training progress of the best agent configuration after 150 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_200.png)\n",
    "*The training progress of the best agent configuration after 200 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_250.png)\n",
    "*The training progress of the best agent configuration after 250 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_300.png)\n",
    "*The training progress of the best agent configuration after 300 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_350.png)\n",
    "*The training progress of the best agent configuration after 350 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_400.png)\n",
    "*The training progress of the best agent configuration after 400 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_450.png)\n",
    "*The training progress of the best agent configuration after 450 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SnaQe agent in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
