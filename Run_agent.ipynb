{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SnaQe - A Q-Learning Network playing Snake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook gives an overview about the development of an agent playing the classical mobile game Snake, using a Q-Net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the the agent, execute the code cell below. Please note, that you will have to wait for 10-15 seconds until you rearrange the windows as the code will produce a thread error otherwise. In case you do not want to start the training, but rather see the results, feel free to move to the [next section](#learning-progress-plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python agent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the agent and model can be found in <code>agent.py</code> and <code>model.py</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning progress plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the training progress of the agent, below are the progress plots for the best agent configuration, which was trained for 490 episodes. The detailed training history with plots every 10 episodes can be found in the folder <code>./training_progress/</code> in this repository.\n",
    "\n",
    "Note, that the score in the top right hand corner is the current record of the agent. While the blue line is tracking the scores of the agent, the green dotted line shows the average score of the agent up to the respective point in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to skip the training progress plots, [click here](#the-snaqe-agent-in-action) to get straight to the video section in which you can see the agent in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_50.png)\n",
    "*The training progress of the best agent configuration after 50 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_100.png)\n",
    "*The training progress of the best agent configuration after 100 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_150.png)\n",
    "*The training progress of the best agent configuration after 150 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_200.png)\n",
    "*The training progress of the best agent configuration after 200 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_250.png)\n",
    "*The training progress of the best agent configuration after 250 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_300.png)\n",
    "*The training progress of the best agent configuration after 300 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_350.png)\n",
    "*The training progress of the best agent configuration after 350 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_400.png)\n",
    "*The training progress of the best agent configuration after 400 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Image\"](./training_progress/plot_450.png)\n",
    "*The training progress of the best agent configuration after 450 episodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SnaQe agent in action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see the agent before it was trained, just randomly moving around and exploring the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Video\"](./videos/Vanilla_Agent_Run.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can see the agent after the training, consistently steering towards the food and avoiding the walls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Video\"](./videos/Trained_Agent_Run.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to watch the videos in a higher quality, please find the [video of the agent before the training](./videos/Vanilla_Agent_Run.mp4) and the [video of the agent after the training](./videos/Trained_Agent_Run.mp4)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
